# Common settings --------------------------------------------------------------
nameOverride: ""
fullnameOverride: ""
imagePullSecrets: []

# Web frontend (serves the React client) --------------------------------------
web:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-web
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
  ingress:
    enabled: false
    hosts:
      - host: todea.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
  env:
    REACT_APP_AGENT_HUB_URL: http://todea-agent-hub:3100/chat

# MCP agent server -------------------------------------------------------------
mcp:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-mcp
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3002
  apiPath: /mcp
  allowOrigins: "*"
  agentModel: gemini-2.5-flash
  env: {}
  googleApiKey: ""

# Agent Hub server ----------------------------------------------------------
agentHub:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-agent-hub
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3100
  allowOrigins: "*"
  agentModel: gemini-2.5-flash
  googleApiKey: ""
  env: {}

# Ollama Hub server ----------------------------------------------------------
ollamaHub:
  enabled: false
  replicaCount: 1
  image:
    repository: todea-ollama-hub
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3200
  allowOrigins: "*"
  agentModel: llama3.2
  ollamaHost: http://todea-ollama:11434
  env: {}

# In-cluster Ollama runtime (optional) ---------------------------------------
ollamaRuntime:
  enabled: false
  replicaCount: 1
  image:
    repository: ollama/ollama
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 11434
  # Model to pull automatically on first startup (empty string to skip).
  # Without persistence, the model is re-downloaded every time the pod restarts.
  model: "llama3.2"
  persistence:
    enabled: false           # true to keep model cache between restarts
    size: 10Gi
    storageClass: ""         # leave empty for default
    accessModes: [ReadWriteOnce]
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
