# Common settings --------------------------------------------------------------
nameOverride: ""
fullnameOverride: ""
imagePullSecrets: []

# Web frontend (serves the React client) --------------------------------------
web:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-web
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 80
  ingress:
    enabled: false
    hosts:
      - host: todea.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
  env:
    REACT_APP_AGENT_HUB_URL: http://todea-agent-hub:3100/chat

# MCP agent server -------------------------------------------------------------
mcp:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-mcp
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3002
  apiPath: /mcp
  allowOrigins: "*"
  agentModel: gemini-2.5-flash
  env: {}
  googleApiKey: ""

# Agent Hub server ----------------------------------------------------------
agentHub:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-agent-hub
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3100
  allowOrigins: "*"
  agentModel: gemini-2.5-flash
  googleApiKey: ""
  env: {}

# Ollama Hub server ----------------------------------------------------------
ollamaHub:
  enabled: false
  replicaCount: 1
  image:
    repository: todea-ollama-hub
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3200
  allowOrigins: "*"
  agentModel: llama3.1:8b
  ollamaHost: http://todea-ollama:11434
  env:
    MCP_SERVER_URL: "http://todea-mcp:3002/mcp"

# Conversation Hub server (shared conversation storage) ----------------------
conversationHub:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-conversation-hub
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3300
  allowOrigins: "*"
  env: {}

# Helm Agent (runs helm/kubectl on behalf of the MCP server) -----------------
helmAgent:
  enabled: true
  replicaCount: 1
  image:
    repository: todea-helm-agent
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3400
  allowOrigins: "*"
  env:
    LOG_LEVEL: DEBUG

# In-cluster Ollama runtime (optional) ---------------------------------------
ollamaRuntime:
  enabled: false
  replicaCount: 1
  image:
    # Use a custom image with the model pre-baked (see servers/ollama-runtime/Dockerfile).
    # Build: docker build -t todea-ollama-runtime:local ./servers/ollama-runtime
    # Import: k3d image import todea-ollama-runtime:local -c <cluster-name>
    repository: todea-ollama-runtime
    tag: local
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 11434
  # Set to the model name to pull it at pod startup (postStart hook).
  # Leave empty when using a pre-baked image â€” the model is already on disk.
  model: ""
  persistence:
    enabled: false           # true to keep model cache between restarts
    size: 10Gi
    storageClass: ""         # leave empty for default
    accessModes: [ReadWriteOnce]
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
